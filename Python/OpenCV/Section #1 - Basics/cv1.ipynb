{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b955f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\lenovo\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from opencv-python) (1.23.5)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\LENOVO\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561e10eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2 as cv\n",
    "print(cv.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229c41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(189, 266, 3)\n"
     ]
    }
   ],
   "source": [
    "img=cv.imread(\"im.jpg\")\n",
    "\n",
    "print(type(img))\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "cv.imshow(\"window\",img) #to show image \n",
    "\n",
    "cv.waitKey(0) #time delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d56f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv.imread(\"im.jpg\")\n",
    "\n",
    "img_gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY) #Gray scale : color-> gray\n",
    "img_gray.shape\n",
    "\n",
    "cv.imshow(\"window\",img_gray)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ca9897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv.imread(\"im.jpg\")\n",
    "\n",
    "imgBlue=img[:,:,0]\n",
    "imgred=img[:,:,2]\n",
    "imgagreen=img[:,:,1]\n",
    "\n",
    "new_img=np.hstack((imgBlue,imgagreen,imgred))\n",
    "\n",
    "cv.imshow(\"window\",new_img)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc3539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"im.jpg\")\n",
    "\n",
    "# Split channels\n",
    "imgBlue = img[:, :, 0]\n",
    "imgGreen = img[:, :, 1]\n",
    "imgRed = img[:, :, 2]\n",
    "\n",
    "# Convert each single channel to a 3-channel image\n",
    "blue_img = cv.merge([imgBlue, imgBlue, imgBlue])\n",
    "green_img = cv.merge([imgGreen, imgGreen, imgGreen])\n",
    "red_img = cv.merge([imgRed, imgRed, imgRed])\n",
    "\n",
    "# Stack them horizontally\n",
    "new_img = np.hstack((blue_img, green_img, red_img))\n",
    "\n",
    "# Show result\n",
    "cv.imshow(\"window\", new_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e744a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2688, 4032, 3)\n",
      "(8064, 12096, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"wal.jpg\")\n",
    "\n",
    "img_res=cv.resize(img,(800,800))\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "imgres=cv.resize(img,(img.shape[1]*3,img.shape[0]*3))\n",
    "print(imgres.shape)\n",
    "# Show result\n",
    "cv.imshow(\"window\", imgres)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8672d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"im.jpg\")\n",
    "\n",
    "img_flip=cv.flip(img,0)\n",
    "\n",
    "# Show result\n",
    "cv.imshow(\"window\", img_flip)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcfe3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"im.jpg\")\n",
    "\n",
    "img_crop=img[0:100,0:100]\n",
    "\n",
    "# Show result\n",
    "cv.imshow(\"window\", img_crop)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59fb8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "# Start webcam\n",
    "capture = cv.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not capture.isOpened():\n",
    "    \n",
    "    print(\"Error: Could not access the webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read frame-by-frame\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    frame=cv.flip(frame,1)\n",
    "    cv.imshow(\"Webcam Feed\", frame)\n",
    "    \n",
    "\n",
    "    # Wait for 'q' key to stop\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release camera and close windows\n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90951c",
   "metadata": {},
   "source": [
    "## RESCALING & RESIZING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "\n",
    "def rescale(frame,scale):\n",
    "    width=int(frame.shape[1]*scale)\n",
    "    height=int(frame.shape[0]*scale)\n",
    "    \n",
    "    dimensions=(width,height)\n",
    "    \n",
    "    return cv.resize(frame,dimensions,interpolation=cv.INTER_LANCZOS4)\n",
    "\n",
    "def changeRes(width,height):\n",
    "    capture.set(3,width)\n",
    "    capture.set(4,height)\n",
    "    \n",
    "    \n",
    "# Start webcam\n",
    "capture = cv.VideoCapture(0)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if not capture.isOpened():\n",
    "    \n",
    "    print(\"Error: Could not access the webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Read frame-by-frame\n",
    "    ret, frame = capture.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    frame=cv.flip(frame,1)\n",
    "    frame=rescale(frame,0.50)\n",
    "    cv.imshow(\"Webcam Feed\", frame)\n",
    "    \n",
    "\n",
    "    # Wait for 'q' key to stop\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release camera and close windows\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da0cca3",
   "metadata": {},
   "source": [
    "## DRAWING IN OPENCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5ffd735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "blank=np.zeros((500,500,3),dtype='uint8')\n",
    "\n",
    "# blank[200:300,300:400]=120,234,124\n",
    "\n",
    "blank=cv.rectangle(blank,(0,0),(250,250),(0,250,0),thickness=-1)\n",
    "blank=cv.circle(blank,(250,250),40,(250,250,0),thickness=-1)\n",
    "blank=cv.line(blank,(0,0),(250,250),(255,255,255),thickness=3)\n",
    "\n",
    "blank=cv.putText(blank,\"VOID\",(215,250),cv.FONT_HERSHEY_COMPLEX,1.0,(0,0,255),2)\n",
    "\n",
    "cv.imshow(\"Window\",blank)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afa691",
   "metadata": {},
   "source": [
    "## BLUR\n",
    "\n",
    "# 🧱 Why do we need a border type?\n",
    "When blurring, OpenCV uses a kernel (in this case, 7×7) that slides over the image. Near the edges, the kernel would partially go outside the image boundary — and OpenCV needs a rule to figure out what values to use in those \"outside\" areas.\n",
    "\n",
    "# 📚 Other border options:\n",
    "\n",
    "| Border Type             | Behavior                                |\n",
    "| ----------------------- | --------------------------------------- |\n",
    "| `cv.BORDER_CONSTANT`    | Pads with a constant value (e.g. black) |\n",
    "| `cv.BORDER_REPLICATE`   | Repeats the edge pixel                  |\n",
    "| `cv.BORDER_REFLECT`     | Mirrors the image at the edge           |\n",
    "| `cv.BORDER_REFLECT_101` | Same as `REFLECT` but skips edge pixel  |\n",
    "| `cv.BORDER_WRAP`        | Wraps around (like tiling)              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3e6f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672, 1008, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "img=cv.imread(\"wal.jpg\")\n",
    "img=cv.resize(img,(img.shape[1]//4,img.shape[0]//4))\n",
    "print(img.shape)\n",
    "cv.imshow('Window',img)\n",
    "\n",
    "blur=cv.GaussianBlur(img,(3,3),cv.BORDER_DEFAULT)\n",
    "cv.imwrite(\"wal2.png\",img)\n",
    "cv.imshow('Window',blur)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a17567",
   "metadata": {},
   "source": [
    "## 📊 Visual Summary:\n",
    "# Operation\tResult\n",
    "cv.Canny\tThin, clean edges\n",
    "\n",
    "cv.dilate\tThicker, more connected edges\n",
    "\n",
    "cv.erode\tThins/removes small noise\n",
    "\n",
    "| Operation    | Iterations = 1   | Iterations = 2 | Iterations = 3       |\n",
    "| ------------ | ---------------- | -------------- | -------------------- |\n",
    "| **Dilation** | Slightly thicker | Thicker        | Very thick/blurred   |\n",
    "| **Erosion**  | Slightly thinned | Smaller object | Object may disappear |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcd05091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('wal2.png')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Canny edge detection\n",
    "edges = cv.Canny(gray, 125, 175)\n",
    "\n",
    "# Kernel for dilation/erosion\n",
    "kernel = np.ones((3, 3), dtype=np.uint8)\n",
    "\n",
    "# Dilation - makes edges thicker\n",
    "dilated = cv.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "# Erosion - cleans up and reduces thickness\n",
    "eroded = cv.erode(dilated, kernel, iterations=1)\n",
    "\n",
    "# Show results\n",
    "cv.imshow('Original Canny', edges)\n",
    "cv.imshow('Dilated', dilated)\n",
    "cv.imshow('After Erosion', eroded)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9417f2",
   "metadata": {},
   "source": [
    "## IMAGE TRANSLATION\n",
    "\n",
    "# TRANSLATION \n",
    "`cv.warpAffine(img, transMat, dim)`\n",
    "\n",
    "-x --> left\n",
    "\n",
    "-y --> up\n",
    "\n",
    "y --> down\n",
    "\n",
    "x ---> right\n",
    "\n",
    "\n",
    "# ROTATION\n",
    "`cv.getRotationMatrix2D(center, angle, scale)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8553e676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=cv.imread(\"wal2.png\")\n",
    "\n",
    "def translation(img,x,y):\n",
    "    transMat=np.float32([[1,0,x],[0,1,y]])\n",
    "    dim=(img.shape[1],img.shape[0])\n",
    "    return cv.warpAffine(img,transMat,dim)\n",
    "\n",
    "translated=translation(img,100,100)\n",
    "cv.imshow('Window',translated)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "938516a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def rotation(img, angle):\n",
    "    (h, w) = img.shape[:2]\n",
    "    center = (w // 2, h // 2)  # Center of the image\n",
    "\n",
    "    # Get the rotation matrix for the specified angle around the center\n",
    "    rotMat = cv.getRotationMatrix2D(center, angle, 1.0)  # scale=1.0 means no scaling\n",
    "\n",
    "    # Apply the affine warp (rotate) with same output size as input\n",
    "    rotated = cv.warpAffine(img, rotMat, (w, h))\n",
    "\n",
    "    return rotated\n",
    "\n",
    "# Usage example\n",
    "img = cv.imread(\"wal2.png\")\n",
    "rotated_img = rotation(img, -45)  # Rotate image by 45 degrees\n",
    "\n",
    "cv.imshow(\"Rotated Image\", rotated_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca110e",
   "metadata": {},
   "source": [
    "## What are Contours?\n",
    "A contour is a curve joining all continuous points along a boundary having the same color or intensity.\n",
    "\n",
    "Think of contours as outlines or shapes detected in an image.\n",
    "\n",
    "Very useful for shape analysis, object detection, and image segmentation.\n",
    "\n",
    "How to find contours in OpenCV?\n",
    "The main function:\n",
    "\n",
    "`contours, hierarchy = cv.findContours(image, mode, method)`\n",
    "\n",
    "## Parameters explained:\n",
    "# 1. **image**\n",
    "Must be a binary image (usually a thresholded or edge-detected image).\n",
    "\n",
    "Contours are found around white regions on black background.\n",
    "\n",
    "Example: output from cv.Canny() or cv.threshold().\n",
    "\n",
    "# 2.**mode (Contour Retrieval Mode)**\n",
    "Defines the hierarchy of contours detected — how contours relate to each other (parent-child).\n",
    "\n",
    "# Important modes:\n",
    "\n",
    "**Mode**\t      **Description**\n",
    "\n",
    "`cv.RETR_EXTERNAL`\tRetrieves only outermost contours (no children).\n",
    "\n",
    "`cv.RETR_LIS`       Retrieves all contours, no hierarchy info.\n",
    "\n",
    "`cv.RETR_CCOMP`\t    Retrieves all contours and organizes into 2 levels: outer boundaries and holes inside them.\n",
    "\n",
    "`cv.RETR_TREE`\t    Retrieves all contours and reconstructs full hierarchy (parents, children, grandchildren).\n",
    "\n",
    "# 3. **method (Contour Approximation Method)**\n",
    "Controls how the contour points are stored — whether all points are stored or some are approximated.\n",
    "\n",
    "**Common methods:**\n",
    "\n",
    "**Method**\t                **Description**\n",
    "\n",
    "`cv.CHAIN_APPROX_NONE`\tStores all points of the contour boundary.\n",
    "\n",
    "`cv.CHAIN_APPROX_SIMPLE`\tCompresses horizontal, vertical, and diagonal segments and leaves only their end points. Saves memory.\n",
    "\n",
    "**What does findContours return?**\n",
    "contours: A Python list of all detected contours. Each contour is a numpy array of points (x, y).\n",
    "\n",
    "hierarchy: Optional output that describes the parent-child relationships between contours. It’s a numpy array of shape (number_of_contours, 4).\n",
    "Each element contains [Next, Previous, First_Child, Parent] indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "076da942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contours found: 1435\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('wal2.png')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv.threshold(gray, 125, 255, cv.THRESH_BINARY)\n",
    "\n",
    "contours, hierarchy = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(f\"Number of contours found: {len(contours)}\")\n",
    "\n",
    "# Draw contours on the original image\n",
    "cv.drawContours(img, contours, -1, (255,255,255), 2)\n",
    "\n",
    "cv.imshow('Contours', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2069a00",
   "metadata": {},
   "source": [
    "## 🔍 Key Differences:\n",
    "| Feature     | Threshold Method                    | Canny Method                  |\n",
    "| ----------- | ----------------------------------- | ----------------------------- |\n",
    "| Input       | Simple binary image (black & white) | Edge map (outlines only)      |\n",
    "| Output look | Fills shapes entirely               | Detects just edges            |\n",
    "| Use case    | Clean, solid objects                | Fine outlines, detailed edges |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "# Load and preprocess image\n",
    "img = cv.imread('wal2.png')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv.Canny(gray, 125, 175)\n",
    "\n",
    "# Find contours from the edge image\n",
    "contours, hierarchy = cv.findContours(edges, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(f\"[Canny] Number of contours found: {len(contours)}\")\n",
    "\n",
    "# Draw contours\n",
    "img_contour = img.copy()\n",
    "cv.drawContours(img_contour, contours, -1, (255, 0, 0), 2)\n",
    "\n",
    "cv.imshow('Contours (Canny)', img_contour)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
